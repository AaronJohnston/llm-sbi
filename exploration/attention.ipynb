{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'the dog walked the man to the park'\n",
    "\n",
    "# tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "# print(tokens)\n",
    "# print(tokenizer.tokenize(prompt))\n",
    "# outputs = model(tokens, output_attentions=True)\n",
    "# print(len(outputs.attentions))\n",
    "# outputs.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertviz import model_view, head_view\n",
    "\n",
    "# model_view(outputs.attentions, tokenizer.convert_ids_to_tokens(tokens[0]))\n",
    "# head_view(outputs.attentions, tokenizer.convert_ids_to_tokens(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal:\n",
    "# 1. Take a prompt.\n",
    "# 2. Generate an answer to the question.\n",
    "# 3. Quantify where attention was paid on each token of the answer.\n",
    "# 4. Visualize that attention. Visualization should work for long passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_shape(name, obj):\n",
    "    # Since this is the top-level inspect call, print the name of the variable.\n",
    "    print(f'{name}: ', end='')\n",
    "    _inspect_shape(obj, len(name) + 2)  # + 2 for ': '\n",
    "\n",
    "\n",
    "def _class_name(obj):\n",
    "    return type(obj).__name__\n",
    "\n",
    "\n",
    "def _inspect_shape(obj, indent):\n",
    "    \"\"\" \n",
    "    Print the given obj. Does not print preceding name or preceding indentation.\n",
    "    Param `indent` should be the indentation level where this obj is being printed. Will be used to print nested properties if necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base Cases (sequences with known-typed contents, tensors, other objects or primitives)\n",
    "    if isinstance(obj, str):\n",
    "        print(f'{_class_name(obj)}[len={len(obj)}]')\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        print(f'{_class_name(obj)}[shape={list(obj.shape)}, sum={obj.sum()}]')\n",
    "    else:\n",
    "\n",
    "        # Dict where contents should be recursively inspected\n",
    "        try:\n",
    "            print(f'{_class_name(obj)}[len={len(obj.items())}]')\n",
    "            for key, val in obj.items():\n",
    "                print(' ' * (indent + 2) + f'{key}: ', end='')\n",
    "                _inspect_shape(val, indent + len(key) + 2)  # + 2 for ': '\n",
    "        except (TypeError, AttributeError):\n",
    "            # Sequence where contents should be recursively inspected\n",
    "            try:\n",
    "                print(f'{_class_name(obj)}[len={len(obj)}]')\n",
    "                for i in range(min(len(obj), 3)):\n",
    "                    print(' ' * (indent + 2) + f'{i}: ', end='')\n",
    "                    # + 2 for ': '\n",
    "                    _inspect_shape(obj[i], indent + len(str(i)) + 2)\n",
    "            except (TypeError, AttributeError):\n",
    "                # Default case if nothing else works\n",
    "                print(f'{_class_name(obj)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def attn_viz(prompt_tokens, generated_sequence_tokens, generated_token_avg_attns):\n",
    "    \"\"\"\n",
    "    prompt_tokens should be simply the token IDs from the prompt\n",
    "    generated_sequence should be the raw sequence from huggingface .generate(), including both prompt and generated tokens.\n",
    "    generated_token_avg_attns should be a sequence with len(generated tokens), where each element is a sequence with len(tokens through generated token, including prompt)\n",
    "    \"\"\"\n",
    "    df = _prepare_attn_df(prompt_tokens, generated_sequence_tokens,\n",
    "                          generated_token_avg_attns)\n",
    "    _show_attn_chart(df)\n",
    "\n",
    "\n",
    "def _prepare_attn_df(prompt_tokens, generated_sequence_tokens, generated_token_avg_attns):\n",
    "    df = pd.DataFrame({'token_id': generated_sequence_tokens, 'token_text': map(\n",
    "        tokenizer.decode, generated_sequence_tokens)})\n",
    "    for i in range(len(generated_sequence_tokens)):\n",
    "        df[f'token_attn_from_{i}'] = 0.0\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def _show_attn_chart(df):\n",
    "    \"\"\"\n",
    "    df should have columns:\n",
    "      token_id: int representation of token\n",
    "      token_text: string representation of token\n",
    "      token_attn_from_{i}: float representing the attention placed on this token by the token with index i in the sequence\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Tensor[shape=[1, 60], sum=254623]\n",
      "outputs: GreedySearchDecoderOnlyOutput[len=3]\n",
      "           sequences: Tensor[shape=[1, 108], sum=454166]\n",
      "           attentions: tuple[len=48]\n",
      "                       0: tuple[len=12]\n",
      "                          0: Tensor[shape=[1, 12, 60, 60], sum=720.0]\n",
      "                          1: Tensor[shape=[1, 12, 60, 60], sum=720.0]\n",
      "                          2: Tensor[shape=[1, 12, 60, 60], sum=720.0]\n",
      "                       1: tuple[len=12]\n",
      "                          0: Tensor[shape=[1, 12, 1, 61], sum=11.999999046325684]\n",
      "                          1: Tensor[shape=[1, 12, 1, 61], sum=12.000000953674316]\n",
      "                          2: Tensor[shape=[1, 12, 1, 61], sum=12.0]\n",
      "                       2: tuple[len=12]\n",
      "                          0: Tensor[shape=[1, 12, 1, 62], sum=12.000000953674316]\n",
      "                          1: Tensor[shape=[1, 12, 1, 62], sum=12.0]\n",
      "                          2: Tensor[shape=[1, 12, 1, 62], sum=11.999999046325684]\n",
      "           past_key_values: tuple[len=12]\n",
      "                            0: tuple[len=2]\n",
      "                               0: Tensor[shape=[1, 12, 107, 64], sum=-2187.402099609375]\n",
      "                               1: Tensor[shape=[1, 12, 107, 64], sum=570.8171997070312]\n",
      "                            1: tuple[len=2]\n",
      "                               0: Tensor[shape=[1, 12, 107, 64], sum=-2905.125]\n",
      "                               1: Tensor[shape=[1, 12, 107, 64], sum=799.8795166015625]\n",
      "                            2: tuple[len=2]\n",
      "                               0: Tensor[shape=[1, 12, 107, 64], sum=-897.89990234375]\n",
      "                               1: Tensor[shape=[1, 12, 107, 64], sum=-732.2595825195312]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3648</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10216</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14935</td>\n",
       "      <td>Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28034</td>\n",
       "      <td>torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>28034</td>\n",
       "      <td>torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>24248</td>\n",
       "      <td>relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1718</td>\n",
       "      <td>took</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1295</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>625</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id token_text\n",
       "0         464        The\n",
       "1        3648       2008\n",
       "2       10216     Summer\n",
       "3       14935   Olympics\n",
       "4       28034      torch\n",
       "..        ...        ...\n",
       "103     28034      torch\n",
       "104     24248      relay\n",
       "105      1718       took\n",
       "106      1295      place\n",
       "107       625       over\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def average_token_attn(token_attn):\n",
    "    layer_avg_attns = []\n",
    "    for layer_idx, layer_attn in enumerate(token_attn):\n",
    "        print('layer_idx', layer_idx)\n",
    "        # Take mean across model's attention heads\n",
    "        layer_avg_attn = layer_attn.squeeze(0).mean(dim=0)\n",
    "        # inspect_shape('layer_avg_attn', layer_avg_attn)\n",
    "        layer_avg_attn_cleaned = torch.concat([\n",
    "            torch.tensor([0.]),  # First entry is null attention, set it to 0\n",
    "            # Remove all tokens except the most recent (since the first token generated has entire prompts' worth of attention generated) and remove the first entry\n",
    "            layer_avg_attn[-1][1:],\n",
    "            torch.tensor([0.]),  # Add a 0 for the current token itself\n",
    "        ])\n",
    "        # inspect_shape('layer_avg_attn_cleaned', layer_avg_attn_cleaned)\n",
    "        layer_avg_attn_normalized = layer_avg_attn_cleaned / layer_avg_attn_cleaned.sum()\n",
    "        # inspect_shape('layer_avg_attn_normalized', layer_avg_attn_normalized)\n",
    "        layer_avg_attns.append(layer_avg_attn_normalized)\n",
    "    # inspect_shape('layer_avg_attns', layer_attn)\n",
    "    return torch.stack(layer_avg_attns).mean(dim=0)\n",
    "\n",
    "\n",
    "def generate_and_attn(prompt):\n",
    "    prompt_tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    inspect_shape('tokens', prompt_tokens)\n",
    "\n",
    "    outputs = model.generate(prompt_tokens, max_new_tokens=48,\n",
    "                             output_attentions=True, return_dict_in_generate=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    inspect_shape('outputs', outputs)\n",
    "    # token_avg_attn = average_token_attn(outputs.attentions[1])\n",
    "    # inspect_shape('token_avg_attn', token_avg_attn)\n",
    "    # print(token_avg_attn)\n",
    "    # for token in outputs.sequences[0]:\n",
    "    #     print(token, tokenizer.decode(token), end=', ')\n",
    "    attn_viz(prompt_tokens, outputs.sequences[0], map(\n",
    "        average_token_attn, outputs.attentions))\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer Olympics, with the theme of \"one world, one dream\". The torch relay took place over 45km with 18 total runners.\n",
    "\n",
    "Q: What was the theme?\n",
    "A:\n",
    "\"\"\".strip()\n",
    "\n",
    "generate_and_attn(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1826, 0.3651, 0.5477, 0.7303])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1, 2, 3, 4])\n",
    "torch.nn.functional.normalize(a, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
